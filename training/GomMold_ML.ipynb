{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GomMold Mold Detection â€“ YOLOv8 Training Notebook\n",
        "\n",
        "**Course**: Software Engineering and AI Application\n",
        "\n",
        "**Team Members**\n",
        "- Nur Shaqeerah\n",
        "- Aina Nur Insyeerah\n",
        "- Nur Ain Syafiqah\n",
        "- Yumni Karmila\n",
        "\n",
        "**Purpose**:  \n",
        "This notebook trains and evaluates a YOLOv8 model for detecting mold and non-mold areas in household environments.\n"
      ],
      "metadata": {
        "id": "UgRQbeYVFLk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install prerequisites\n",
        "!pip install ultralytics\n"
      ],
      "metadata": {
        "id": "eHgKQmEateBP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "id": "JZ1TwnZtrFF3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Dataset\n",
        "\n",
        "The dataset was created using Roboflow (mold_detection_GomMold).  \n",
        "It contains two classes:\n",
        "\n",
        "- **Mold**\n",
        "- **No Mold**\n",
        "\n",
        "The dataset has been augmented with:\n",
        "- Horizontal flips  \n",
        "- Brightness/contrast adjustments  \n",
        "- Exposure variations  \n",
        "\n",
        "### ðŸ”— Roboflow Dataset Link\n",
        "Dataset source (Roboflow project page):\n",
        "\n",
        "ðŸ‘‰ https://universe.roboflow.com/gommold-8opye/mold_detection_gommold-if0p0\n",
        "\n",
        "This link provides access to dataset details, versions, and annotations.\n",
        "(download the latest version from there)\n"
      ],
      "metadata": {
        "id": "DFyAaHnFIQeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Download Dataset from Roboflow\n",
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "\n",
        "# âš ï¸ IMPORTANT:\n",
        "# Insert your own Roboflow API key here if you want to reproduce the experiment.\n",
        "# The key has been removed for security in the public GitHub version.\n",
        "\n",
        "rf = Roboflow(api_key=\"8X3RHgilXHsCh0cPcUSj\")\n",
        "project = rf.workspace(\"gommold-8opye\").project(\"mold_detection_gommold-if0p0\")\n",
        "version = project.version(4)\n",
        "dataset = version.download(\"yolov8\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ww9NjviryHs0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if u downloaded the data manually from the link, unzip the file\n",
        "\n",
        "!unzip /content/mold_detection_GomMold.yolov8.zip -d /content/\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dGoHlOI5Um3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/gdrive/MyDrive/GomMold_AIML\"\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MpnNnaf3Vdrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load YOLOv8 Model\n",
        "We start training from `yolov8n.pt` using transfer learning."
      ],
      "metadata": {
        "id": "9VaIAj1mLGxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")"
      ],
      "metadata": {
        "id": "faLnH1vPR8ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Train the Model\n"
      ],
      "metadata": {
        "id": "Q9vX5IxuLTw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(\n",
        "    data=\"/content/mold_detection_GomMold-4/data.yaml\",  # path to dataset\n",
        "    epochs=50,        # 30â€“50 recommended\n",
        "    imgsz=640,        # image size\n",
        "    batch=16,\n",
        "    patience=10,      # early stopping if no improvement\n",
        "    lr0=0.01,         # initial learning rate\n",
        "    augment=True      # enable augmentation\n",
        ")"
      ],
      "metadata": {
        "id": "gJfnjalALKUM",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the trained model to drive\n",
        "\n",
        "!cp /content/runs/detect/train/weights/best.pt /content/gdrive/MyDrive/GomMold_AIML/new_best4.pt #change this to your drive directory\n"
      ],
      "metadata": {
        "id": "Zs_xVq7OGHND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7GnC-OqAki66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Training Metrics & Graphs\n",
        "YOLO automatically generates:\n",
        "- results.png\n",
        "- loss curves\n",
        "- mAP curves\n",
        "- confusion matrix\n"
      ],
      "metadata": {
        "id": "q3cXPEWxLnzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image('/content/runs/detect/train/results.png')\n"
      ],
      "metadata": {
        "id": "D-o0u6UeL2h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image('/content/runs/detect/train/confusion_matrix.png')"
      ],
      "metadata": {
        "id": "xHxYexRlL6bY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install firebase-admin\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8gJNvFrckkHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"/content/runs/detect/train/weights/best.pt\")\n",
        "\n",
        "model.export(format=\"onnx\", opset=12)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "emeNuZ3dmU_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Inference Samples\n"
      ],
      "metadata": {
        "id": "P57gzeLgMM62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir sample_test\n",
        "\n",
        "# copy a few images from test set\n",
        "!cp /content/mold_detection_GomMold-4/test/images/*.jpg sample_test/\n",
        "\n",
        "# run prediction\n",
        "results = model.predict(\"/content/sample_test\", save=True)\n"
      ],
      "metadata": {
        "id": "-uYQLYgPMN4k",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "Ld_HKGPukRKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import firebase_admin\n",
        "\n",
        "# reset if already initialized\n",
        "if firebase_admin._apps:\n",
        "    firebase_admin.delete_app(firebase_admin.get_app())\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pL5VNt45lN1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cred = credentials.Certificate(\"/content/gommold-c6654-firebase-adminsdk-fbsvc-bf7bea4cc9.json\")\n",
        "\n",
        "firebase_admin.initialize_app(cred, {\n",
        "    \"storageBucket\": \"gommold-c6654.firebasestorage.app\"\n",
        "})\n"
      ],
      "metadata": {
        "id": "yi4DmjFTn6jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bucket = storage.bucket()\n"
      ],
      "metadata": {
        "id": "ESVd8SZFoHF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blob = bucket.blob(\"models/best.onnx\")\n",
        "blob.upload_from_filename(\"/content/runs/detect/train/weights/best.onnx\")\n",
        "blob.make_public()\n",
        "\n",
        "print(\"MODEL URL:\", blob.public_url)\n"
      ],
      "metadata": {
        "id": "mz0baYLll0MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Conclusion\n",
        "\n",
        "The YOLOv8 model performed well in detecting mold vs non-mold images.  \n",
        "Further improvements include:\n",
        "- Increasing dataset variety\n",
        "- Improving low-light images\n",
        "- Adding more â€œNo Moldâ€ clean wall images to reduce false positives\n"
      ],
      "metadata": {
        "id": "aFD1S6vjM5oD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test onnx file tadi"
      ],
      "metadata": {
        "id": "x3dH_RBdpnTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ueqCMgcSpow8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n"
      ],
      "metadata": {
        "id": "S0KjperIqG01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_path = \"/content/runs/detect/train/weights/best.onnx\"\n",
        "session = ort.InferenceSession(onnx_path, providers=[\"CPUExecutionProvider\"])\n",
        "\n",
        "print(\"ONNX loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "6HOPfoX9qK7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n"
      ],
      "metadata": {
        "id": "xD655tqxqOKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(\"/content/1-b2ad256f.png\")\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img_resized = cv2.resize(img, (640, 640))\n",
        "\n",
        "# normalize\n",
        "input_data = img_resized / 255.0\n",
        "input_data = np.transpose(input_data, (2, 0, 1))  # HWC â†’ CHW\n",
        "input_data = np.expand_dims(input_data, axis=0).astype(np.float32)\n"
      ],
      "metadata": {
        "id": "YIYArtl_qV1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = session.run(None, {\"images\": input_data})\n",
        "print(\"ONNX inference ran successfully!\")\n",
        "print(\"Output length:\", len(outputs))\n"
      ],
      "metadata": {
        "id": "PcWTSRZxqfHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = session.run(None, {\"images\": input_data})\n",
        "print(\"ONNX inference ran successfully!\")\n",
        "print(\"Output length:\", len(outputs))\n",
        "\n",
        "output = outputs[0]\n",
        "print(\"Output shape:\", output.shape)\n"
      ],
      "metadata": {
        "id": "NL_gfkzPrRVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime opencv-python pillow numpy\n",
        "\n"
      ],
      "metadata": {
        "id": "pBqWEdI2ztUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "onnx_path = \"/content/runs/detect/train/weights/best.onnx\"\n",
        "session = ort.InferenceSession(onnx_path, providers=[\"CPUExecutionProvider\"])\n"
      ],
      "metadata": {
        "id": "TOb1a3jyzuCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "test_image_path = list(uploaded.keys())[0]  # takes the uploaded image\n"
      ],
      "metadata": {
        "id": "8vzdjtK_ztlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(test_image_path)\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img_resized = cv2.resize(img_rgb, (640, 640))\n",
        "\n",
        "input_data = img_resized / 255.0\n",
        "input_data = np.transpose(input_data, (2, 0, 1))  # HWC â†’ CHW\n",
        "input_data = input_data[np.newaxis, :, :, :].astype(np.float32)  # add batch dim\n"
      ],
      "metadata": {
        "id": "g2px4Aclz9-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = session.run(None, {\"images\": input_data})\n",
        "pred = outputs[0]   # shape (1, 6, 8400)\n"
      ],
      "metadata": {
        "id": "y0CIf97C0AUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = pred[0]  # remove batch dim\n",
        "\n",
        "# extract each component\n",
        "x = pred[0]\n",
        "y = pred[1]\n",
        "w = pred[2]\n",
        "h = pred[3]\n",
        "conf = pred[4]\n",
        "cls = pred[5]\n"
      ],
      "metadata": {
        "id": "UoEKsbFv0D1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_threshold = 0.25  # adjust if needed\n",
        "mask = conf > score_threshold\n",
        "\n",
        "x = x[mask]\n",
        "y = y[mask]\n",
        "w = w[mask]\n",
        "h = h[mask]\n",
        "conf = conf[mask]\n",
        "cls = cls[mask]\n"
      ],
      "metadata": {
        "id": "wtdxQEq10Fvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boxes = []\n",
        "\n",
        "for i in range(len(x)):\n",
        "    xc, yc, bw, bh = x[i], y[i], w[i], h[i]\n",
        "    xmin = int((xc - bw/2) * img.shape[1] / 640)\n",
        "    ymin = int((yc - bh/2) * img.shape[0] / 640)\n",
        "    xmax = int((xc + bw/2) * img.shape[1] / 640)\n",
        "    ymax = int((yc + bh/2) * img.shape[0] / 640)\n",
        "    boxes.append([xmin, ymin, xmax, ymax, conf[i]])\n"
      ],
      "metadata": {
        "id": "OtyJ8TGM0HdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (xmin, ymin, xmax, ymax, score) in boxes:\n",
        "    cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
        "    cv2.putText(img, f\"mold: {score:.2f}\", (xmin, ymin - 5),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n"
      ],
      "metadata": {
        "id": "yxBNv72K0KWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(img)\n"
      ],
      "metadata": {
        "id": "HfFPtz_70MXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Detections:\", len(boxes))\n",
        "for b in boxes:\n",
        "    print(\"Box:\", b)\n"
      ],
      "metadata": {
        "id": "yPHes1c40f9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# -------------------------\n",
        "# 1. Load ONNX model\n",
        "# -------------------------\n",
        "onnx_path = \"/content/models_best.onnx\"\n",
        "session = ort.InferenceSession(onnx_path, providers=[\"CPUExecutionProvider\"])\n",
        "\n",
        "# -------------------------\n",
        "# 2. Upload test image\n",
        "# -------------------------\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "test_image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# -------------------------\n",
        "# 3. Preprocess image\n",
        "# -------------------------\n",
        "img = cv2.imread(test_image_path)\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "h0, w0 = img.shape[:2]  # original dims\n",
        "\n",
        "img_resized = cv2.resize(img_rgb, (640, 640))\n",
        "input_data = img_resized / 255.0\n",
        "input_data = np.transpose(input_data, (2, 0, 1))  # HWC â†’ CHW\n",
        "input_data = np.expand_dims(input_data, axis=0).astype(np.float32)\n",
        "\n",
        "# -------------------------\n",
        "# 4. Inference\n",
        "# -------------------------\n",
        "outputs = session.run(None, {\"images\": input_data})\n",
        "pred = outputs[0][0]   # shape -> (6, 8400)\n",
        "\n",
        "# -------------------------\n",
        "# 5. Extract components\n",
        "# -------------------------\n",
        "x = pred[0]\n",
        "y = pred[1]\n",
        "w = pred[2]\n",
        "h = pred[3]\n",
        "conf = pred[4]\n",
        "cls = pred[5]\n",
        "\n",
        "# -------------------------\n",
        "# 6. Filter by confidence\n",
        "# -------------------------\n",
        "threshold = 0.30\n",
        "mask = conf > threshold\n",
        "\n",
        "x = x[mask]\n",
        "y = y[mask]\n",
        "w = w[mask]\n",
        "h = h[mask]\n",
        "conf = conf[mask]\n",
        "\n",
        "# -------------------------\n",
        "# 7. Convert XYWH â†’ XYXY (scaled back to original img)\n",
        "# -------------------------\n",
        "boxes = []\n",
        "for i in range(len(x)):\n",
        "    xc, yc, bw, bh = x[i], y[i], w[i], h[i]\n",
        "    xmin = int((xc - bw/2) * w0 / 640)\n",
        "    ymin = int((yc - bh/2) * h0 / 640)\n",
        "    xmax = int((xc + bw/2) * w0 / 640)\n",
        "    ymax = int((yc + bh/2) * h0 / 640)\n",
        "    boxes.append([xmin, ymin, xmax, ymax, conf[i]])\n",
        "\n",
        "# -------------------------\n",
        "# 8. Print detections\n",
        "# -------------------------\n",
        "print(\"Detections:\", len(boxes))\n",
        "for b in boxes:\n",
        "    print(\"Box:\", b)\n",
        "\n",
        "# -------------------------\n",
        "# 9. Draw boxes\n",
        "# -------------------------\n",
        "for (xmin, ymin, xmax, ymax, score) in boxes:\n",
        "    cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
        "    cv2.putText(img, f\"Mold {score:.2f}\", (xmin, ymin - 5),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "\n",
        "# -----------------\n"
      ],
      "metadata": {
        "id": "KqMZpydx00We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n"
      ],
      "metadata": {
        "id": "ieG7BtuA1thX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(img)\n"
      ],
      "metadata": {
        "id": "TGyD3ewL1uIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DRAW FINAL BOXES\n",
        "for (xmin, ymin, xmax, ymax, score) in boxes:\n",
        "    cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0,255,0), 2)\n",
        "    cv2.putText(img, f\"Mold {score:.2f}\", (xmin, ymin-5),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)\n",
        "\n",
        "# SHOW IMAGE\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(img)\n"
      ],
      "metadata": {
        "id": "yd_X1_0x1tZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(session.get_outputs())\n"
      ],
      "metadata": {
        "id": "-HmWZ9M43wgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = session.get_outputs()[0]\n",
        "print(\"Output name:\", out.name)\n",
        "print(\"Output shape:\", out.shape)\n",
        "print(\"Output type:\", out.type)\n"
      ],
      "metadata": {
        "id": "l8tAVfhu4Edn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}